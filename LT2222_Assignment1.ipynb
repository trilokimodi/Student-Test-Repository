{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "facial-family",
      "metadata": {
        "id": "facial-family"
      },
      "source": [
        "# LT2222 V23 Assignment 1: Intent Classification\n",
        "\n",
        "In this assignment you will be working with data from the *Slot and Intent Detection for Low Resource\n",
        "language varieties (SID4LR)* shared task. \n",
        "\n",
        "Given an utterance, the task consists on identifying the intent of the speaker along with the key spans that require an action from the system. For example, given the utterance *Add reminder to swim at 11am tomorrow*, the intent is *add reminder*, while the slots are *to do* and *datetime*. **Here we'll focus on intent classification only.**\n",
        "\n",
        "The dataset consists of 13 languages (en, de-st, de, da, nl, it, sr, id, ar, zh, kk, tr, ja).\n",
        "\n",
        "For more details about the data please check [this paper](https://aclanthology.org/2021.naacl-main.197.pdf) by van der Goot et al., (2021)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "blond-capture",
      "metadata": {
        "id": "blond-capture"
      },
      "source": [
        "## General instructions\n",
        "\n",
        "You will do all the work inside this notebook and submit your edited notebook back into Canvas. You many not copy code from elsewhere, but you can use functions from any module currently available on mltgpu, where the notebook will be tested. A major goal of the assignment is, in fact, for you to find them yourself and apply them. Only edit the notebook in the places where we specify you should do so.\n",
        "\n",
        "You will need to give reasonable, but not excessively verbose, documentation of your code so that we understand what you did.\n",
        "\n",
        "**The assignment is officially due at 23:59 CET on Thursday February 16, 2023. There are 33 points and 5 bonus points.**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "under-celebrity",
      "metadata": {
        "id": "under-celebrity"
      },
      "source": [
        "### 1. Choose a language and download the corresponding train, validation and test data splits. (2 points)\n",
        "\n",
        "https://bitbucket.org/robvanderg/sid4lr/src/master/xSID-0.4/\n",
        "\n",
        "Store the chosen data into a directory `data/`. You may use any method you prefer (e.g., command line tools, graphic interphase, copy+paste, ...). "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*I downloaded zip file, extracted and manually uploaded the english language files in the data folder.*"
      ],
      "metadata": {
        "id": "fOedfoHI6JAp"
      },
      "id": "fOedfoHI6JAp"
    },
    {
      "cell_type": "markdown",
      "id": "shaped-omaha",
      "metadata": {
        "id": "shaped-omaha"
      },
      "source": [
        "### 2. Import all necessary modules here. (1 point)\n",
        "\n",
        "**Enter and run your code below.**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install conllu\n",
        "from IPython.display import clear_output\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "38Sty5RGHGn7"
      },
      "id": "38Sty5RGHGn7",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "institutional-conservative",
      "metadata": {
        "id": "institutional-conservative"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import conllu\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn import preprocessing\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import permutation_test_score"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "sought-chancellor",
      "metadata": {
        "id": "sought-chancellor"
      },
      "source": [
        "### 3. Import the data into Python. (7 points)\n",
        "\n",
        "Write code to read the data into Python. You should have two variables: one corresponding to the utterances or `x` and another one corresponding to the intents or `y`. \n",
        "\n",
        "**Hint:** both the #slot information and the IOB column are **not** used in this assignment.\n",
        "\n",
        "Note that the amount of data varies depending on the language selected. \n",
        "\n",
        "**Enter and run your code below. You may insert additional code boxes and text boxes for comments.**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*The function takes path, filename as mandatory inputs. After a series of simple operations, the functions returns dataframe. The dataframe contains two columns. The feature column contains full sentences i.e. utterrances and the response column contains intents. By default, the function removes all duplicate entries in the dataset.*"
      ],
      "metadata": {
        "id": "cAwsS1cH717o"
      },
      "id": "cAwsS1cH717o"
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dataframe_from_Conll(path, filename, canRemoveDuplicates=True): \n",
        "    dataset_path = os.path.join(path, filename)\n",
        "    data = open(dataset_path, mode='r', encoding='utf-8')\n",
        "    data = data.read()\n",
        "    sentences = conllu.parse(data, fields=[\"id\", \"form\", \"intent\"])\n",
        "    xT = list()\n",
        "    yT = list()\n",
        "    for iSentence in sentences:\n",
        "        sentenceString = list()\n",
        "        intentString = list()\n",
        "        for iToken in list(iSentence):\n",
        "            sentenceString.append(iToken['form'])\n",
        "            intentString.append(iToken['intent'])\n",
        "        xT.append(' '.join(sentenceString))\n",
        "        yT.append(list(set(intentString))[0])\n",
        "\n",
        "    data = {'X': xT, 'y': yT}\n",
        "    df = pd.DataFrame(data=data)\n",
        "    if (canRemoveDuplicates == True):\n",
        "        df.drop_duplicates(inplace=True)\n",
        "        df.reset_index(drop=True, inplace=True)\n",
        "    return df"
      ],
      "metadata": {
        "id": "5S0aOuBdkVGl"
      },
      "id": "5S0aOuBdkVGl",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# As instructed the data is in data folder and I assume that CWD is one directory before data dir.\n",
        "dataset = os.path.join(os.getcwd(), 'data')\n",
        "df_train = get_dataframe_from_Conll(dataset, 'en.train.conll', canRemoveDuplicates=True)\n",
        "df_valid = get_dataframe_from_Conll(dataset, 'en.valid.conll', canRemoveDuplicates=True)"
      ],
      "metadata": {
        "id": "-uSfqAbNl5Mp"
      },
      "id": "-uSfqAbNl5Mp",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ic05HH9xkUgg"
      },
      "id": "ic05HH9xkUgg"
    },
    {
      "cell_type": "markdown",
      "id": "mature-thread",
      "metadata": {
        "id": "mature-thread"
      },
      "source": [
        "### 4. Explore your features. (11 points)\n",
        "\n",
        "In this part of the assignment, we work with count features only. You need to convert the features into sparce vectors. You may use tools from Scikit-learn and/or Pandas to do this. Scikit-learn in particular has very handy tools for the vectorization of categorical features, for example [CountVectorizer()](https://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction). \n",
        "\n",
        "After converting your features into sparse vectors, answer the following questions: \n",
        "\n",
        "a) How many features are there?\n",
        "\n",
        "b) What are the most common features?\n",
        "\n",
        "**Enter and run your code below. You may insert additional code boxes and text boxes for comments.**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Count Vectorizer generates one hot encoded vectors. The feature size is equal to the total number of unique tokens. A token is a word in the train data. Note that count vectorizer only considers words with minimum length 2, hence, words like 'a', ',', '?' etc are automatically filtered out.*\n",
        "\n",
        "*The most common feature is the word that is present with highest frequency considering all utterances at once.*\n",
        "\n",
        "*The function fit_transform converts the given set of textual strings to one hot encoded vectors. This function should only be used by training data. For validation and test data, transform function should be used to preserve the feature space.*"
      ],
      "metadata": {
        "id": "MOiSGW2o8SEd"
      },
      "id": "MOiSGW2o8SEd"
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = CountVectorizer()\n",
        "def get_one_hot_encoded_features(X=df_train['X'], vectorizer=vectorizer, isTrainData=True):\n",
        "    if (isTrainData == True):\n",
        "        return vectorizer.fit_transform(X)\n",
        "    else:\n",
        "        return vectorizer.transform(X)\n",
        "\n",
        "def get_number_of_features(one_hot_encoded_features):\n",
        "    return one_hot_encoded_features.shape[1]\n",
        "\n",
        "def get_most_common_features(one_hot_encoded_features, vectorizer=vectorizer):\n",
        "    return vectorizer.get_feature_names_out()[one_hot_encoded_features.sum(axis=0).argmax()]"
      ],
      "metadata": {
        "id": "WXs89W3Jmffo"
      },
      "id": "WXs89W3Jmffo",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "XTrain_OneHotEncodedFeatures = get_one_hot_encoded_features(X=df_train['X'], isTrainData=True)\n",
        "XValid_OneHotEncodedFeatures = get_one_hot_encoded_features(X=df_valid['X'], isTrainData=False)"
      ],
      "metadata": {
        "id": "-gGhtbfvn5DW"
      },
      "id": "-gGhtbfvn5DW",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "number_of_features = get_number_of_features(XTrain_OneHotEncodedFeatures)\n",
        "print(f'The total number of features = {number_of_features}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KuxOm7xMoRRJ",
        "outputId": "e48a7b5d-6c78-4313-8d46-fa6302023695"
      },
      "id": "KuxOm7xMoRRJ",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The total number of features = 12971\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "most_common_feature = get_most_common_features(XTrain_OneHotEncodedFeatures)\n",
        "print(f'The most common feature is = {most_common_feature}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6H_8pnKoS2z",
        "outputId": "4f92ce91-de09-415d-f4b9-609c98783946"
      },
      "id": "k6H_8pnKoS2z",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The most common feature is = the\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*There are 12971 features.*"
      ],
      "metadata": {
        "id": "OcOWhGIWl-4G"
      },
      "id": "OcOWhGIWl-4G"
    },
    {
      "cell_type": "markdown",
      "source": [
        "*The most common feature is the word 'the'. It is not suprising that the word 'the' is dominant feature.*"
      ],
      "metadata": {
        "id": "-i4S8AbMowNq"
      },
      "id": "-i4S8AbMowNq"
    },
    {
      "cell_type": "markdown",
      "id": "eight-america",
      "metadata": {
        "id": "eight-america"
      },
      "source": [
        "### 5. Using Scikit-learn fit either a Decision Tree model or a Multinomial Naive Bayes model. (3 points)\n",
        "\n",
        "**Enter and run your code below.**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*A label encoder helps in converting the string based response variable to numbers. This doesn't have any significance to model performance, but, it is generally a good practice to convert them. The fit method does the encoding and the function transform converts a given set of string labels to integers labels using the results of fit.*"
      ],
      "metadata": {
        "id": "5dCjP_P89FsU"
      },
      "id": "5dCjP_P89FsU"
    },
    {
      "cell_type": "code",
      "source": [
        "labelEncoder = preprocessing.LabelEncoder()\n",
        "def make_numeric_labels(yTrain=df_train['y']):\n",
        "    labelEncoder.fit(list(set(yTrain)))\n",
        "    \n",
        "def get_numeric_labels(y=df_train['y'], labelEncoder=labelEncoder):\n",
        "    return labelEncoder.transform(y)\n",
        "\n",
        "make_numeric_labels()"
      ],
      "metadata": {
        "id": "OCCDQPYFooWJ"
      },
      "id": "OCCDQPYFooWJ",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_true = get_numeric_labels(df_train['y'])\n",
        "y_valid_true = get_numeric_labels(df_valid['y'])"
      ],
      "metadata": {
        "id": "WSO-k4FgqBTI"
      },
      "id": "WSO-k4FgqBTI",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*I chose naive bayes classifier. The function fit, takes in vectorized features and response variable to fit a naive bayes model in this case. The vectorized features, here, are one hot encoded vectors, but they can be any embeddings.*\n",
        "\n",
        "*The fit method should always be fed with training data and not validation or test data.*"
      ],
      "metadata": {
        "id": "pYP4ftGb-Gfx"
      },
      "id": "pYP4ftGb-Gfx"
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = GaussianNB()\n",
        "def make_NB_model(one_hot_encoded_features=XTrain_OneHotEncodedFeatures, numeric_labels=y_train_true, classifier=GaussianNB()):\n",
        "    classifier.fit(one_hot_encoded_features.toarray(), numeric_labels)\n",
        "\n",
        "make_NB_model(classifier=classifier)"
      ],
      "metadata": {
        "id": "c4dzArFcp6-_"
      },
      "id": "c4dzArFcp6-_",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "working-controversy",
      "metadata": {
        "id": "working-controversy"
      },
      "source": [
        "### 6. Using [Scikit-learn.metrics](https://scikit-learn.org/stable/modules/model_evaluation.html) evaluate your model using the development (aka as validation) set. (9 points)\n",
        "\n",
        "In order to evaluate your model you need to use the development set. Keep in mind that you need to pre-process the dev set in the same way that you pre-process your train set. \n",
        "\n",
        "Answer the following questions:\n",
        "\n",
        "a) What is the accuracy?\n",
        "\n",
        "b) What are the precision, recall and f1?\n",
        "\n",
        "c) How do your results compare with those reported in the paper?\n",
        "\n",
        "**Enter and run your code below. You may insert additional code boxes and text boxes for comments.**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*The function predict, uses the fitted model to predict the labels on test or valid data. If model fit is improved iteratively, for example in neural networks, then predict function can take training labels as well calculate cost for cost functions.*"
      ],
      "metadata": {
        "id": "4wIqs0VE-mNa"
      },
      "id": "4wIqs0VE-mNa"
    },
    {
      "cell_type": "code",
      "source": [
        "def get_predicted_labels(one_hot_encoded_features_predict=XValid_OneHotEncodedFeatures, classifier=classifier):\n",
        "    return classifier.predict(one_hot_encoded_features_predict.toarray())\n",
        "\n",
        "y_valid_pred = get_predicted_labels(XValid_OneHotEncodedFeatures)"
      ],
      "metadata": {
        "id": "EaodRztJrysc"
      },
      "id": "EaodRztJrysc",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*The method accuracy_score, precision_score, recall_score, f1_score are all used to evaluate model performance. All these methods also support multi-class labels which is the case here. For multi-class labels, average 'macro' is used to treat all classes equally.*\n",
        "\n",
        "*These results can be influence with the average method chosen, and depending on the problem statement, they can chosen if for example true negatives is preferred over false negatives.* \n",
        "\n",
        "*For text classification, I think all classes should be treated equally and hence I chose macro.*"
      ],
      "metadata": {
        "id": "d2LVjiXj_Ic7"
      },
      "id": "d2LVjiXj_Ic7"
    },
    {
      "cell_type": "code",
      "source": [
        "def get_evaluation_metrics_scores(yTrue, yPred):\n",
        "    model_accuracy = accuracy_score(yTrue, yPred)\n",
        "    print(f'The accuracy of the model = {model_accuracy:.4f}')\n",
        "\n",
        "    model_precision = precision_score(yTrue, yPred, average='macro')\n",
        "    print(f'The precision of the model with macro average = {model_precision:.4f}')\n",
        "\n",
        "    model_recall = recall_score(yTrue, yPred, average='macro')\n",
        "    print(f'The recall of the model with macro average = {model_recall:.4f}')\n",
        "\n",
        "    model_f1score = f1_score(yTrue, yPred, average='macro')\n",
        "    print(f'The f1 score of the model with macro average = {model_f1score:.4f}')"
      ],
      "metadata": {
        "id": "K1DIREsZt-_P"
      },
      "id": "K1DIREsZt-_P",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_evaluation_metrics_scores(y_valid_true, y_valid_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T2YV8987uvOX",
        "outputId": "c952b368-e94d-4da0-ad89-26184dc6e042"
      },
      "id": "T2YV8987uvOX",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy of the model = 0.6154\n",
            "The precision of the model with macro average = 0.4515\n",
            "The recall of the model with macro average = 0.4910\n",
            "The f1 score of the model with macro average = 0.4459\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# If you are interested in training data predictions - Uncomment the two below lines\n",
        "# y_train_pred = get_predicted_labels(XTrain_OneHotEncodedFeatures)\n",
        "# get_evaluation_metrics_scores(y_train_true, y_train_pred)"
      ],
      "metadata": {
        "id": "Tv9l4QVRvG8n"
      },
      "id": "Tv9l4QVRvG8n",
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*The model accuracy when tested on validation data resulted in 61.54%.*\n",
        "*whereas the model precision, recall and f1 scores all turned out to be in range* [45, 50]%.\n",
        "\n",
        "*Even though the accuracy is relatively high, the model is not good enough. Accuracy can lead to biased results when there is a class imbalance in the training data. This can be seen in the histogram plot shown below.*\n",
        "\n",
        "*The F1-score reflects better performance of model when there is class imbalance. Since the F1-score is below 50%, we can state that there is much higher scope to improve model performance.*\n",
        "\n",
        "*When the training data is tested to itself, the one hot model resulted a 66% f1-score which also reflects that one-hot encoders models bias themselves to training data instead of generalizing.*\n",
        "\n",
        "*In the research article, for english language using mBERT models, the researchers obtained above 95% f1-scores. This is likely due to the feature representations and much advanced models i.e. recurrent networks with attention models, etc.*"
      ],
      "metadata": {
        "id": "zU3_wKk9v3tf"
      },
      "id": "zU3_wKk9v3tf"
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(y_train_true)\n",
        "plt.xlabel('Encoded intent')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Histogram to show class imbalance')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "SGEiFVa83DuV",
        "outputId": "18882d49-b1ed-4adb-e27c-b95591ec9487"
      },
      "id": "SGEiFVa83DuV",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Histogram to show class imbalance')"
            ]
          },
          "metadata": {},
          "execution_count": 25
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "final-framework",
      "metadata": {
        "id": "final-framework"
      },
      "source": [
        "### 7. Bonus - Improve the results obtained in step 6. (5 points)\n",
        "\n",
        "Some options that you may explore are to:\n",
        "\n",
        "- Target the data (slide or subset according to some criterion).\n",
        "- Target the pre-processing.\n",
        "- Consider different features.\n",
        "\n",
        " Then explain why your adjustments produced improved results. \n",
        "\n",
        "**Enter and run your code below. You may insert additional code boxes and text boxes for comments and write-up.**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Curiosity Attempt (Not improvement)"
      ],
      "metadata": {
        "id": "mYD1Q9_KZp64"
      },
      "id": "mYD1Q9_KZp64"
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Here, the goal is to try cross validation and check if there is features is completely independent of response. The number of permutations to sample response is just 2 for faster computation.*"
      ],
      "metadata": {
        "id": "tmq8VZtVYsMb"
      },
      "id": "tmq8VZtVYsMb"
    },
    {
      "cell_type": "code",
      "source": [
        "cv = StratifiedKFold(2, shuffle=True, random_state=0)\n",
        "\n",
        "clf = GaussianNB()\n",
        "score, perm, pvalue = permutation_test_score(\n",
        "    clf, XTrain_OneHotEncodedFeatures.toarray(), y_train_true, scoring=\"f1_macro\", cv=cv, n_permutations=2\n",
        ")"
      ],
      "metadata": {
        "id": "_oxomzXUDl6i"
      },
      "id": "_oxomzXUDl6i",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_Q7smMrWyf7",
        "outputId": "ae7b6a85-79f6-499b-a692-e58eec9664bb"
      },
      "id": "k_Q7smMrWyf7",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6178825939738952"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "perm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KIuFbLLKXFyP",
        "outputId": "72f6676f-4f9c-43ee-ca71-f52fb544eff8"
      },
      "id": "KIuFbLLKXFyP",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.03813041, 0.03675536])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pvalue"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CumWmK5WXHdw",
        "outputId": "ff1d39c7-4d7d-4c42-c8b3-43226fbf8fcc"
      },
      "id": "CumWmK5WXHdw",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3333333333333333"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Only 2 permuted models were developed and the p-value equals 0.333 which is the max possible i.e. best score for this operation i.e. a max score of 1 / (num of permutations + 1) can be obtained. Since we got this, we can state that there is a correlation between feature matrix and response and the poor f1-score is not a random score.\n",
        "\n",
        "The trust on permutation_test_score can is low due to less number of permutations and less number of k-folds. However, this was skipped due to long processing time."
      ],
      "metadata": {
        "id": "gU9pX_FYY8KN"
      },
      "id": "gU9pX_FYY8KN"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Improvement Attempt"
      ],
      "metadata": {
        "id": "YnFbxdDxZlRw"
      },
      "id": "YnFbxdDxZlRw"
    },
    {
      "cell_type": "markdown",
      "source": [
        "The goal is to reduce features by hashing all words that are numbers to a single word. E.g. A sentence like 'Set alarm for 730' will become 'Set alarm for someNumber'."
      ],
      "metadata": {
        "id": "MSL7zk-ZXvB9"
      },
      "id": "MSL7zk-ZXvB9"
    },
    {
      "cell_type": "code",
      "source": [
        "# Improvement - Preprocessing numbers to reduce number of features\n",
        "def get_dataframe_from_Conll_hash_numbers(path, filename, canRemoveDuplicates=True): \n",
        "    dataset_path = os.path.join(path, filename)\n",
        "    data = open(dataset_path, mode='r', encoding='utf-8')\n",
        "    data = data.read()\n",
        "    sentences = conllu.parse(data, fields=[\"id\", \"form\", \"intent\"])\n",
        "    xT = list()\n",
        "    yT = list()\n",
        "    for iSentence in sentences:\n",
        "        sentenceString = list()\n",
        "        intentString = list()\n",
        "        for iToken in list(iSentence):\n",
        "            if iToken['form'].isdigit():\n",
        "                sentenceString.append('someNumber')\n",
        "            else:\n",
        "                sentenceString.append(iToken['form'])\n",
        "            intentString.append(iToken['intent'])\n",
        "        xT.append(' '.join(sentenceString))\n",
        "        yT.append(list(set(intentString))[0])\n",
        "\n",
        "    data = {'X': xT, 'y': yT}\n",
        "    df = pd.DataFrame(data=data)\n",
        "    if (canRemoveDuplicates == True):\n",
        "        df.drop_duplicates(inplace=True)\n",
        "        df.reset_index(drop=True, inplace=True)\n",
        "    return df"
      ],
      "metadata": {
        "id": "dBXJEISUMEXv"
      },
      "id": "dBXJEISUMEXv",
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = get_dataframe_from_Conll_hash_numbers(dataset, 'en.train.conll', canRemoveDuplicates=True)\n",
        "df_valid = get_dataframe_from_Conll_hash_numbers(dataset, 'en.valid.conll', canRemoveDuplicates=True)"
      ],
      "metadata": {
        "id": "m7Tfum1zMnRo"
      },
      "id": "m7Tfum1zMnRo",
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = CountVectorizer()\n",
        "def get_one_hot_encoded_features(X=df_train['X'], vectorizer=vectorizer, isTrainData=True):\n",
        "    if (isTrainData == True):\n",
        "        return vectorizer.fit_transform(X)\n",
        "    else:\n",
        "        return vectorizer.transform(X)\n",
        "\n",
        "def get_number_of_features(one_hot_encoded_features):\n",
        "    return one_hot_encoded_features.shape[1]\n",
        "\n",
        "def get_most_common_features(one_hot_encoded_features, vectorizer=vectorizer):\n",
        "    return vectorizer.get_feature_names_out()[one_hot_encoded_features.sum(axis=0).argmax()]"
      ],
      "metadata": {
        "id": "9HgpG9WTNQOE"
      },
      "execution_count": 43,
      "outputs": [],
      "id": "9HgpG9WTNQOE"
    },
    {
      "cell_type": "code",
      "source": [
        "XTrain_OneHotEncodedFeatures = get_one_hot_encoded_features(X=df_train['X'], isTrainData=True)\n",
        "XValid_OneHotEncodedFeatures = get_one_hot_encoded_features(X=df_valid['X'], isTrainData=False)"
      ],
      "metadata": {
        "id": "SJXjZkORNQOF"
      },
      "execution_count": 44,
      "outputs": [],
      "id": "SJXjZkORNQOF"
    },
    {
      "cell_type": "markdown",
      "source": [
        "The number of features reduced from 12971 to 12799. Not so significant."
      ],
      "metadata": {
        "id": "bhMn5DJMYGlr"
      },
      "id": "bhMn5DJMYGlr"
    },
    {
      "cell_type": "code",
      "source": [
        "number_of_features = get_number_of_features(XTrain_OneHotEncodedFeatures)\n",
        "print(f'The total number of features = {number_of_features}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0167327e-6951-47da-dbaf-7908f4771f18",
        "id": "9IYFDNLUNQOF"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The total number of features = 12799\n"
          ]
        }
      ],
      "id": "9IYFDNLUNQOF"
    },
    {
      "cell_type": "code",
      "source": [
        "most_common_feature = get_most_common_features(XTrain_OneHotEncodedFeatures)\n",
        "print(f'The most common feature is = {most_common_feature}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1abe3f87-041e-437e-a3e1-b9220fcb8580",
        "id": "TVS2JdkxNQOF"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The most common feature is = the\n"
          ]
        }
      ],
      "id": "TVS2JdkxNQOF"
    },
    {
      "cell_type": "code",
      "source": [
        "labelEncoder = preprocessing.LabelEncoder()\n",
        "def make_numeric_labels(yTrain=df_train['y']):\n",
        "    labelEncoder.fit(list(set(yTrain)))\n",
        "    \n",
        "def get_numeric_labels(y=df_train['y'], labelEncoder=labelEncoder):\n",
        "    return labelEncoder.transform(y)\n",
        "\n",
        "make_numeric_labels()"
      ],
      "metadata": {
        "id": "BrKHRtOjNQOF"
      },
      "execution_count": 47,
      "outputs": [],
      "id": "BrKHRtOjNQOF"
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_true = get_numeric_labels(df_train['y'])\n",
        "y_valid_true = get_numeric_labels(df_valid['y'])"
      ],
      "metadata": {
        "id": "u28ZdxTsNQOG"
      },
      "execution_count": 48,
      "outputs": [],
      "id": "u28ZdxTsNQOG"
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = GaussianNB()\n",
        "def make_NB_model(one_hot_encoded_features=XTrain_OneHotEncodedFeatures, numeric_labels=y_train_true, classifier=GaussianNB()):\n",
        "    classifier.fit(one_hot_encoded_features.toarray(), numeric_labels)\n",
        "\n",
        "make_NB_model(classifier=classifier)"
      ],
      "metadata": {
        "id": "LI0ryPFMNQOG"
      },
      "execution_count": 49,
      "outputs": [],
      "id": "LI0ryPFMNQOG"
    },
    {
      "cell_type": "code",
      "source": [
        "def get_predicted_labels(one_hot_encoded_features_predict=XValid_OneHotEncodedFeatures, classifier=classifier):\n",
        "    return classifier.predict(one_hot_encoded_features_predict.toarray())\n",
        "\n",
        "y_valid_pred = get_predicted_labels(XValid_OneHotEncodedFeatures)"
      ],
      "metadata": {
        "id": "QMjFcCURNQOG"
      },
      "execution_count": 50,
      "outputs": [],
      "id": "QMjFcCURNQOG"
    },
    {
      "cell_type": "code",
      "source": [
        "def get_evaluation_metrics_scores(yTrue, yPred):\n",
        "    model_accuracy = accuracy_score(yTrue, yPred)\n",
        "    print(f'The accuracy of the model = {model_accuracy:.4f}')\n",
        "\n",
        "    model_precision = precision_score(yTrue, yPred, average='macro')\n",
        "    print(f'The precision of the model with macro average = {model_precision:.4f}')\n",
        "\n",
        "    model_recall = recall_score(yTrue, yPred, average='macro')\n",
        "    print(f'The recall of the model with macro average = {model_recall:.4f}')\n",
        "\n",
        "    model_f1score = f1_score(yTrue, yPred, average='macro')\n",
        "    print(f'The f1 score of the model with macro average = {model_f1score:.4f}')"
      ],
      "metadata": {
        "id": "2fVUSpHhNQOG"
      },
      "execution_count": 51,
      "outputs": [],
      "id": "2fVUSpHhNQOG"
    },
    {
      "cell_type": "code",
      "source": [
        "get_evaluation_metrics_scores(y_valid_true, y_valid_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e7ad9fa-454e-4df5-adf5-27d27e0fe336",
        "id": "kH1f5phdNQOG"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy of the model = 0.6250\n",
            "The precision of the model with macro average = 0.4671\n",
            "The recall of the model with macro average = 0.5226\n",
            "The f1 score of the model with macro average = 0.4588\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "id": "kH1f5phdNQOG"
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model didnot improve due to not so good preprocessing."
      ],
      "metadata": {
        "id": "klZ-GG4IYOmb"
      },
      "id": "klZ-GG4IYOmb"
    },
    {
      "cell_type": "markdown",
      "id": "handled-clarity",
      "metadata": {
        "id": "handled-clarity"
      },
      "source": [
        "### Submission\n",
        "\n",
        "Submit this notebook with all your code in Canvas. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "contemporary-rabbit",
      "metadata": {
        "id": "contemporary-rabbit"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}