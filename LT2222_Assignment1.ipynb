{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/trilokimodi/Student-Test-Repository/blob/master/LT2222_Assignment1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "facial-family",
      "metadata": {
        "id": "facial-family"
      },
      "source": [
        "# LT2222 V23 Assignment 1: Intent Classification\n",
        "\n",
        "In this assignment you will be working with data from the *Slot and Intent Detection for Low Resource\n",
        "language varieties (SID4LR)* shared task. \n",
        "\n",
        "Given an utterance, the task consists on identifying the intent of the speaker along with the key spans that require an action from the system. For example, given the utterance *Add reminder to swim at 11am tomorrow*, the intent is *add reminder*, while the slots are *to do* and *datetime*. **Here we'll focus on intent classification only.**\n",
        "\n",
        "The dataset consists of 13 languages (en, de-st, de, da, nl, it, sr, id, ar, zh, kk, tr, ja).\n",
        "\n",
        "For more details about the data please check [this paper](https://aclanthology.org/2021.naacl-main.197.pdf) by van der Goot et al., (2021)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "blond-capture",
      "metadata": {
        "id": "blond-capture"
      },
      "source": [
        "## General instructions\n",
        "\n",
        "You will do all the work inside this notebook and submit your edited notebook back into Canvas. You many not copy code from elsewhere, but you can use functions from any module currently available on mltgpu, where the notebook will be tested. A major goal of the assignment is, in fact, for you to find them yourself and apply them. Only edit the notebook in the places where we specify you should do so.\n",
        "\n",
        "You will need to give reasonable, but not excessively verbose, documentation of your code so that we understand what you did.\n",
        "\n",
        "**The assignment is officially due at 23:59 CET on Thursday February 16, 2023. There are 33 points and 5 bonus points.**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "under-celebrity",
      "metadata": {
        "id": "under-celebrity"
      },
      "source": [
        "### 1. Choose a language and download the corresponding train, validation and test data splits. (2 points)\n",
        "\n",
        "https://bitbucket.org/robvanderg/sid4lr/src/master/xSID-0.4/\n",
        "\n",
        "Store the chosen data into a directory `data/`. You may use any method you prefer (e.g., command line tools, graphic interphase, copy+paste, ...). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "latest-prophet",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "latest-prophet",
        "outputId": "6e902eb7-ce98-4869-ab60-f7291668637b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output"
      ],
      "metadata": {
        "id": "XImtx0bEFE-l"
      },
      "id": "XImtx0bEFE-l",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = \"/content/drive/My Drive/MLSNLP/Data/\""
      ],
      "metadata": {
        "id": "XgoNkQeXFI5f"
      },
      "id": "XgoNkQeXFI5f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "shaped-omaha",
      "metadata": {
        "id": "shaped-omaha"
      },
      "source": [
        "### 2. Import all necessary modules here. (1 point)\n",
        "\n",
        "**Enter and run your code below.**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install conllu\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "38Sty5RGHGn7"
      },
      "id": "38Sty5RGHGn7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "institutional-conservative",
      "metadata": {
        "id": "institutional-conservative"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import conllu\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn import preprocessing\n",
        "from sklearn.metrics import confusion_matrix, plot_confusion_matrix\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "sought-chancellor",
      "metadata": {
        "id": "sought-chancellor"
      },
      "source": [
        "### 3. Import the data into Python. (7 points)\n",
        "\n",
        "Write code to read the data into Python. You should have two variables: one corresponding to the utterances or `x` and another one corresponding to the intents or `y`. \n",
        "\n",
        "**Hint:** both the #slot information and the IOB column are **not** used in this assignment.\n",
        "\n",
        "Note that the amount of data varies depending on the language selected. \n",
        "\n",
        "**Enter and run your code below. You may insert additional code boxes and text boxes for comments.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "detailed-scheduling",
      "metadata": {
        "id": "detailed-scheduling"
      },
      "outputs": [],
      "source": [
        "train_dataset = dataset + 'en.train.conll'\n",
        "train_data = open(train_dataset, mode='r', encoding='utf-8')\n",
        "\n",
        "a = train_data.read()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = conllu.parse(a, fields=[\"id\", \"form\", \"intent\"])"
      ],
      "metadata": {
        "id": "fIV008dKKNaZ"
      },
      "id": "fIV008dKKNaZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split_func = lambda line, i: line[i].split(\"/\")\n",
        "sentences = conllu.parse(a, fields=[\"id\", \"form\", \"intent\"], field_parsers={\"intent\": split_func})"
      ],
      "metadata": {
        "id": "2b-n0jxBQxeZ"
      },
      "id": "2b-n0jxBQxeZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list(sentences[3])[8]['form']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "FgX9eFcfKnGO",
        "outputId": "d6b90836-8507-48cf-e8f8-700662beb6c5"
      },
      "id": "FgX9eFcfKnGO",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'bay'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xTrain = list()\n",
        "yTrain = list()\n",
        "for iSentence in sentences:\n",
        "    sentenceString = list()\n",
        "    intentString = list()\n",
        "    for iToken in list(iSentence):\n",
        "        sentenceString.append(iToken['form'])\n",
        "        intentString.append(iToken['intent'])\n",
        "    xTrain.append(' '.join(sentenceString))\n",
        "    yTrain.append(list(set(intentString))[0])"
      ],
      "metadata": {
        "id": "Q_EQwxkHc0cZ"
      },
      "id": "Q_EQwxkHc0cZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = {'X': xTrain, 'y': yTrain}\n",
        "df = pd.DataFrame(data=train_data)"
      ],
      "metadata": {
        "id": "-M0Pa22GfBXB"
      },
      "id": "-M0Pa22GfBXB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop_duplicates(inplace=True)\n",
        "df.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "aHCaLJ0ChFzC"
      },
      "id": "aHCaLJ0ChFzC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XXJcHUhJl7gF",
        "outputId": "f0aadd94-0839-4492-d2d5-1f2ea237cb48"
      },
      "id": "XXJcHUhJl7gF",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(37163, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mature-thread",
      "metadata": {
        "id": "mature-thread"
      },
      "source": [
        "### 4. Explore your features. (11 points)\n",
        "\n",
        "In this part of the assignment, we work with count features only. You need to convert the features into sparce vectors. You may use tools from Scikit-learn and/or Pandas to do this. Scikit-learn in particular has very handy tools for the vectorization of categorical features, for example [CountVectorizer()](https://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction). \n",
        "\n",
        "After converting your features into sparse vectors, answer the following questions: \n",
        "\n",
        "a) How many features are there?\n",
        "\n",
        "b) What are the most common features?\n",
        "\n",
        "**Enter and run your code below. You may insert additional code boxes and text boxes for comments.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "liable-cement",
      "metadata": {
        "id": "liable-cement"
      },
      "outputs": [],
      "source": [
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit_transform(df['X'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "chp8HpHZlhRV",
        "outputId": "55b4edb0-b948-4036-fa3e-f238098cc2cd"
      },
      "id": "chp8HpHZlhRV",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(37163, 12971)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are 12971 features. Note that Count Vectorizer removes features with less than 2 characters. For example tokens like 'a' or ',' are excluded."
      ],
      "metadata": {
        "id": "OcOWhGIWl-4G"
      },
      "id": "OcOWhGIWl-4G"
    },
    {
      "cell_type": "code",
      "source": [
        "X.sum(axis=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9NUmAC0RnQFr",
        "outputId": "b58c688b-f522-4472-9e9e-d26c12df9be5"
      },
      "id": "9NUmAC0RnQFr",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "matrix([[257,   1,   1, ...,   4,   7,   1]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer.get_feature_names_out()[X.sum(axis=0).argmax()]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "0vogk2m4oBdJ",
        "outputId": "8c6c1eb3-0cd7-472e-e6af-48978a7e20e3"
      },
      "id": "0vogk2m4oBdJ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'the'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The most common feature is the word 'the'."
      ],
      "metadata": {
        "id": "-i4S8AbMowNq"
      },
      "id": "-i4S8AbMowNq"
    },
    {
      "cell_type": "markdown",
      "id": "eight-america",
      "metadata": {
        "id": "eight-america"
      },
      "source": [
        "### 5. Using Scikit-learn fit either a Decision Tree model or a Multinomial Naive Bayes model. (3 points)\n",
        "\n",
        "**Enter and run your code below.**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "le = preprocessing.LabelEncoder()"
      ],
      "metadata": {
        "id": "WxPD9qkWrHiD"
      },
      "id": "WxPD9qkWrHiD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "le.fit(list(set(df['y'])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yV0ElXWwrLy0",
        "outputId": "87cf21b8-b357-4e77-cc66-d3bd86dafdc6"
      },
      "id": "yV0ElXWwrLy0",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LabelEncoder()"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = le.transform(df['y'])"
      ],
      "metadata": {
        "id": "rNx7r5axrWrq"
      },
      "id": "rNx7r5axrWrq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yPD9bPc6rcoJ",
        "outputId": "b03e0530-d9d4-4a2c-a9af-562c1556930b"
      },
      "id": "yPD9bPc6rcoJ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(37163,)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = GaussianNB()\n",
        "classifier.fit(X.toarray(), y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zUKXSQmLqHX3",
        "outputId": "4c135ec1-2f41-4993-8259-17c7df12816e"
      },
      "id": "zUKXSQmLqHX3",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GaussianNB()"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "working-controversy",
      "metadata": {
        "id": "working-controversy"
      },
      "source": [
        "### 6. Using [Scikit-learn.metrics](https://scikit-learn.org/stable/modules/model_evaluation.html) evaluate your model using the development (aka as validation) set. (9 points)\n",
        "\n",
        "In order to evaluate your model you need to use the development set. Keep in mind that you need to pre-process the dev set in the same way that you pre-process your train set. \n",
        "\n",
        "Answer the following questions:\n",
        "\n",
        "a) What is the accuracy?\n",
        "\n",
        "b) What are the precision, recall and f1?\n",
        "\n",
        "c) How do your results compare with those reported in the paper?\n",
        "\n",
        "**Enter and run your code below. You may insert additional code boxes and text boxes for comments.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "positive-university",
      "metadata": {
        "id": "positive-university"
      },
      "outputs": [],
      "source": [
        "y_pred = classifier.predict(X.toarray())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rMhTigHArrZr",
        "outputId": "2b00eea6-1a5b-4e7d-ce4b-728884c1d211"
      },
      "id": "rMhTigHArrZr",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(37163,)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y, y_pred)\n",
        "print(cm)"
      ],
      "metadata": {
        "id": "gSCeKW9J_MaE"
      },
      "id": "gSCeKW9J_MaE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_confusion_matrix(classifier, X.toarray(), y, display_labels=['alt.atheism',\n",
        " 'comp.graphics',\n",
        " 'comp.os.ms-windows.misc',\n",
        " 'comp.sys.ibm.pc.hardware'], cmap=plt.cm.Blues)"
      ],
      "metadata": {
        "id": "FTe4jamv_ZkF"
      },
      "id": "FTe4jamv_ZkF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm.accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "FtPRwKtaG355",
        "outputId": "1f29b017-e84d-4dee-b2e2-87f8c493751c"
      },
      "id": "FtPRwKtaG355",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-7ad8f21597a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'accuracy'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "final-framework",
      "metadata": {
        "id": "final-framework"
      },
      "source": [
        "### 7. Bonus - Improve the results obtained in step 6. (5 points)\n",
        "\n",
        "Some options that you may explore are to:\n",
        "\n",
        "- Target the data (slide or subset according to some criterion).\n",
        "- Target the pre-processing.\n",
        "- Consider different features.\n",
        "\n",
        " Then explain why your adjustments produced improved results. \n",
        "\n",
        "**Enter and run your code below. You may insert additional code boxes and text boxes for comments and write-up.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "imposed-complaint",
      "metadata": {
        "id": "imposed-complaint"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "handled-clarity",
      "metadata": {
        "id": "handled-clarity"
      },
      "source": [
        "### Submission\n",
        "\n",
        "Submit this notebook with all your code in Canvas. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "contemporary-rabbit",
      "metadata": {
        "id": "contemporary-rabbit"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "suspended-sunset",
      "metadata": {
        "id": "suspended-sunset"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}